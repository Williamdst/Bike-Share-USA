{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.7/site-packages (2.8.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the password in \n",
    "PGHOST = 'tripdatabase2.cmaaautpgbsf.us-east-2.rds.amazonaws.com'\n",
    "PGDATABASE = ''\n",
    "PGUSER = 'postgres'\n",
    "PGPASSWORD = 'Josh1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success: ('PostgreSQL 12.5 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11), 64-bit',) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Database Context Manager\n",
    "try:   \n",
    "    # Set up a connection to the postgres server.    \n",
    "    conn = psycopg2.connect(user = PGUSER,\n",
    "                            port = \"5432\",\n",
    "                            password = PGPASSWORD,\n",
    "                            host = PGHOST,\n",
    "                            database = PGDATABASE)\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()   \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    record = cursor.fetchone()\n",
    "    print(\"Connection Success:\", record,\"\\n\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Table Cleaning I: Handling Outliers - Speed\n",
    "In this section we are going to modify trips whose speed (MPH) are physically unlikely. Luckily, we have a reference from the different services on what a speed outlier might look like. According to them, their pedal assisted e-bikes can go up to 18 MPH. In the sport of cycling, although not on a pedal assisted bike, a reasonably experienced cyclist can reach over 19 MPH. Using a nicer whole number, we'll use 20 MPH as a conservative cutoff and anything over that will be considered an outlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already took the \"delete data\" path multiple times in this project. Although there is still millions of rows of data after all those deletes, let's make an effort to conserve data. To handle speed outliers, we are going to cap the speed at 20 MPH. Any trip that has a speed over 20 MPH we are going to adjust the trip duration in a way that when the speed is calculated it will result in 20 MPH. $$\\frac{Distance}{\\frac{Duration}{60}} = 20$$\n",
    "\n",
    "$$\\frac{60 \\times Distance}{20} = Duration$$\n",
    "\n",
    "$$3 \\times Distance = Duration$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import Queries\n",
    "import importlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Queries' from '/root/Citi-Bike-Expansion/Queries.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(Queries) # Delete this for the publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = ['bay', 'blue', 'capital', 'citi', 'divvy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in services:\n",
    "    speed_outliers_query = f\"\"\"\n",
    "            UPDATE trips.{service}_trip\n",
    "               SET speed = 20,\n",
    "                   duration = distance * 3\n",
    "             WHERE speed > 20;\n",
    "             \"\"\"\n",
    "    \n",
    "    Queries.execute_query(conn,speed_outliers_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to update the speed column on the upper end because we are fairly certain that the bikes can't go over 20 MPH, but what about speed on the lower end. Specifically the trips that have a speed of 0 MPH which is a result of a round trip. Round trips occur when a rider starts and ends at the same station, resulting in a distance of zero miles and a speed also being zero. So how do we deal with this? Almost the same as with the upper speed value. We are going to set the speed to be the average 6 MPH. This time instead of finding the duration, we are going to find the distance. \n",
    "$$\\frac{Distance}{\\frac{Duration}{60}} = 6$$\n",
    "\n",
    "$$Distance = \\frac{6 \\times Duration}{60}$$\n",
    "\n",
    "$$Distance = \\frac{Duration}{10}$$\n",
    "\n",
    "\n",
    "\n",
    "***Note on Average Speed:*** *It was found by excluding the 0 MPH trips and after the 20 MPH adjustment and was 6 MPH for every bike service*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in services:\n",
    "    roundtrip_outliers_query = f\"\"\"\n",
    "                UPDATE trips.{service}_trip\n",
    "                   SET speed = 6,\n",
    "                       distance = duration / 10\n",
    "                 WHERE distance = 0;\n",
    "                 \"\"\"\n",
    "    Queries.execute_query(conn, roundtrip_outliers_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Table Cleaning II: Removing Time Errors - Start Time After End Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytrip with a starttime that was greater than an endtime is an error and will get deleted. It is possible that the two values were just swapped, but the cost of swapping them is more expensive than the trips were worth. Additionally, it's just a small amount of data that it's better to just remove them. The operations of the swap are:\n",
    "- Find the incorrect values\n",
    "- Move them to a temporary table with the correct order\n",
    "- Delete them from the original table\n",
    "- Reinsert them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in services:\n",
    "    Queries.delete_time_swaps(conn, service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Table Cleaning III: Removing Outliers - Trip Duration\n",
    "Before we remove outliers, we have to define what an outlier is. First let's get a feeling for how the trip duration values are distributed. The trip tables range from 7M to 111M trips, which means we can't query the entire table everytime we want to analyze something. For each table we will take a saple of 1M rows. Our sampling needs to fufill three criteria:\n",
    "- The sampling needs to be random\n",
    "- The sampling needs to be large enough\n",
    "- The query needs to be decently fast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sampling Procedure\n",
    "\n",
    "Unfortunately the ideal Bernoulli sampling in PostgresSQL meets the random condition, but is way too slow for our needs. And the System sampling, although fast enough, isn't truly random. To overcome these limitations, we will use the System sampling for speed and then make the selection of the rows random. The sampling process is as follows:\n",
    "- System sample 1% of the data from a table\n",
    "- Order the results of that sample randomly (ORDER BY RANDOM())\n",
    "- Take the first 20,000 rows (100,000 for CitiBike)\n",
    "- Repeat the previous steps 50 times (10 for CitiBike)\n",
    "\n",
    "*Note: there is a chance that there are duplicate rows in the sampling. The more trips that a service has, the less likely repeats will appear.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_sample = Queries.get_random_rows(conn, 'bay', samples = 1000000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_sample = Queries.get_random_rows(conn, 'blue', samples = 1000000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_sample = Queries.get_random_rows(conn, 'capital', samples = 1000000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "citi_sample = Queries.get_random_rows(conn, 'citi', samples = 1000000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy_sample = Queries.get_random_rows(conn, 'divvy', samples = 1000000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bay</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>15.991732</td>\n",
       "      <td>186.108139</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.12</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.820000</td>\n",
       "      <td>90228.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>26.624014</td>\n",
       "      <td>752.104980</td>\n",
       "      <td>1.02</td>\n",
       "      <td>6.98</td>\n",
       "      <td>11.80</td>\n",
       "      <td>19.820000</td>\n",
       "      <td>392706.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>19.651630</td>\n",
       "      <td>338.997864</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.68</td>\n",
       "      <td>11.43</td>\n",
       "      <td>19.549999</td>\n",
       "      <td>214555.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citi</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>16.872683</td>\n",
       "      <td>179.344574</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.35</td>\n",
       "      <td>10.63</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>46147.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divvy</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>20.709711</td>\n",
       "      <td>365.922180</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>192769.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean         std   min   25%    50%        75%  \\\n",
       "bay      1000000.0  15.991732  186.108139  0.02  6.12   9.90  15.820000   \n",
       "blue     1000000.0  26.624014  752.104980  1.02  6.98  11.80  19.820000   \n",
       "capital  1000000.0  19.651630  338.997864  0.02  6.68  11.43  19.549999   \n",
       "citi     1000000.0  16.872683  179.344574  1.00  6.35  10.63  18.469999   \n",
       "divvy    1000000.0  20.709711  365.922180  0.02  7.00  12.00  21.000000   \n",
       "\n",
       "                   max  \n",
       "bay       90228.796875  \n",
       "blue     392706.406250  \n",
       "capital  214555.421875  \n",
       "citi      46147.011719  \n",
       "divvy    192769.125000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([bay_sample.duration.describe(), \n",
    "              blue_sample.duration.describe(),\n",
    "              capital_sample.duration.describe(),\n",
    "              citi_sample.duration.describe(),\n",
    "              divvy_sample.duration.describe()\n",
    "             ], index = ['bay','blue','capital','citi','divvy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our duration distrubtions look the same: trip duration is drastically skewed to the right. Because of the skew our mean and standard deviation aren't reliable measures to use for outlier detection. Our standard deviations range from 2.7hrs to 11hrs, yet our median values are all under 12m and the 75th percentiles barely breach the 20m mark. \n",
    "\n",
    "It appears that quantiles are a good measure to use to determine outliers and seem to be more representative of real life. However, each different service has their own distributions so there isn't a one-size-fits-all quantile measure to use. The 99th percentile may be 66m for one service, but 160m for another. So the question becomes: ***Is there a universal duration cutoff value that can be used for all bike share services?***\n",
    "\n",
    "To find the answer to that question, we first need to asses whether \"Bike Share Behavior\" is universal. ***Do people that use Bike Share services behave the same way, regardless of the service?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Share Behavior I - Duration Statistical Tests\n",
    "\n",
    "When we ask the question whether riders of bike share services behave the same way, what we are asking is if the underlying distributions are the same across all the services. We are looking at one dependent variable (duration), across five different services, on distributions that aren't normal. With those three characteristics we can use a Kruskal-Wallis Test to see if the underlying distributions are the same. \n",
    "\n",
    "- The Null Hypotheses: $H_0:$ The samples all originate from the same distribution and have the same median values\n",
    "- The Alternative Hypotheses: $H_1:$ At least one sample originates from a different distribution and has a different median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal-Wallis H Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=42476.35929180635, pvalue=0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kruskal(bay_sample.duration, blue_sample.duration, capital_sample.duration, citi_sample.duration, divvy_sample.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of 0 there is enough evidence, at any signficant level, to reject the null hypothesis that the sample all originate form the same distribution and have the same median values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Mann-Whitney U Test\n",
    "From the Kruskal-Wallis test, we only know that at least one sample originates from a different distribution and we don't know how bike services compare pairwise. In this section we will compare each bike share service to another on a pairwise level. The null hypothesis is the same as the Kruskal-Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayWheels Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MannwhitneyuResult(statistic=432718288960.5, pvalue=0.0),\n",
       " MannwhitneyuResult(statistic=444568916420.5, pvalue=0.0),\n",
       " MannwhitneyuResult(statistic=469393838548.0, pvalue=0.0),\n",
       " MannwhitneyuResult(statistic=427988173571.0, pvalue=0.0))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(bay_sample.duration, blue_sample.duration), \\\n",
    "stats.mannwhitneyu(bay_sample.duration, capital_sample.duration), \\\n",
    "stats.mannwhitneyu(bay_sample.duration, citi_sample.duration), \\\n",
    "stats.mannwhitneyu(bay_sample.duration, divvy_sample.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BlueBike Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MannwhitneyuResult(statistic=489600684066.5, pvalue=1.962683214484485e-143),\n",
       " MannwhitneyuResult(statistic=464290382392.0, pvalue=0.0),\n",
       " MannwhitneyuResult(statistic=493846914443.0, pvalue=1.2376110963922516e-51))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(blue_sample.duration, capital_sample.duration), \\\n",
    "stats.mannwhitneyu(blue_sample.duration, citi_sample.duration), \\\n",
    "stats.mannwhitneyu(blue_sample.duration, divvy_sample.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CapitalBike Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MannwhitneyuResult(statistic=475259769860.5, pvalue=0.0),\n",
       " MannwhitneyuResult(statistic=483904096488.5, pvalue=0.0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(capital_sample.duration, citi_sample.duration), \\\n",
    "stats.mannwhitneyu(capital_sample.duration, divvy_sample.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CitiBike Comparisonsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=458944167547.5, pvalue=0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(citi_sample.duration, divvy_sample.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every null hypothesis got rejected and no two bike share service samples come from the same underlying distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station Table Update I: Station Status\n",
    "The ecosystem of stations in a bike share service is always changing. They add new stations, removes stations, and occasionally moves stations to nearby locations. In this section we are going to add two new columns to each station table in the stations schema called birth and death. \n",
    "\n",
    "The birth column will represent the date of the first trip that was taken from the station. The death column represents the date of the last trip that was taken from the station. Stations are considered dead if there wasn't a trip within the last month of 2020. **Any station that is still active will have a null value in the death column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in services:\n",
    "    add_columns_query = f\"\"\"\n",
    "            ALTER TABLE stations.{service}_station\n",
    "            ADD COLUMN birth TIMESTAMP,\n",
    "            ADD COLUMN death TIMESTAMP;\n",
    "            \"\"\"\n",
    "    Queries.execute_query(conn, add_columns_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the Bay Wheels data requires a format that is slightly different from the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_certificate_query = \"\"\"\n",
    "                WITH timestamps AS (\n",
    "                    SELECT DISTINCT startid, \n",
    "                                    MIN(DATE_TRUNC('day',starttime)::date) over w AS birth, \n",
    "                                    MAX(DATE_TRUNC('day',starttime)::date) over w AS death\n",
    "                      FROM trips.bay_trip\n",
    "                    WINDOW w as (PARTITION BY startid)\n",
    "                )\n",
    "            \n",
    "                UPDATE stations.bay_station AS s\n",
    "                   SET birth = ts.birth,\n",
    "                       death = ts.death\n",
    "                  FROM timestamps AS ts\n",
    "                 WHERE s.stationid = ts.startid;\n",
    "                \"\"\"  \n",
    "Queries.execute_query(conn, birth_certificate_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queries.birth_certificate(conn, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queries.birth_certificate(conn, 'capital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queries.birth_certificate(conn, 'citi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queries.birth_certificate(conn, 'divvy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for service in services:\n",
    "    set_death_null = f\"\"\"\n",
    "        UPDATE stations.{service}_station\n",
    "           SET death = NULL\n",
    "         WHERE death <= '2020-12-31'\n",
    "           AND death > '2020-12-01';\n",
    "        \"\"\"\n",
    "    Queries.execute_query(conn, set_death_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
