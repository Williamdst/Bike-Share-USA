{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the Database\n",
    "\n",
    "Each citibike file has the same format, the colomns in the files are:\n",
    "- Trip Duration (seconds)\n",
    "- Start Date & Time\n",
    "- End Date & Time\n",
    "- Start Station ID\n",
    "- Start Station Name\n",
    "- Start Station Latitude\n",
    "- Start Station Longitude\n",
    "- End Date & Time\n",
    "- End Station ID\n",
    "- End Station Name\n",
    "- End Station Latitude\n",
    "- End Station Longitude\n",
    "- Bike ID\n",
    "- User Type\n",
    "- Gender\n",
    "- Year of Birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DatabaseDiagram.png\" width=\"600\" height=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.7/site-packages (2.8.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the password in \n",
    "PGHOST = 'tripdatabase.cmaaautpgbsf.us-east-2.rds.amazonaws.com'\n",
    "PGDATABASE = ''\n",
    "PGUSER = 'postgres'\n",
    "PGPASSWORD = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success: ('PostgreSQL 12.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11), 64-bit',) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    # Set up a connection to the postgres server.    \n",
    "    conn = psycopg2.connect(user = PGUSER,\n",
    "                            port = \"5432\",\n",
    "                            password = PGPASSWORD,\n",
    "                            host = PGHOST,\n",
    "                            database = PGDATABASE)\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()   \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    record = cursor.fetchone()\n",
    "    print(\"Connection Success:\", record,\"\\n\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Staging Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Using cached s3fs-0.5.1-py3-none-any.whl (21 kB)\n",
      "Collecting aiobotocore>=1.0.1\n",
      "  Using cached aiobotocore-1.1.2-py3-none-any.whl (45 kB)\n",
      "Collecting fsspec>=0.8.0\n",
      "  Using cached fsspec-0.8.4-py3-none-any.whl (91 kB)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs) (1.11.2)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Using cached aioitertools-0.7.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.17.45,>=1.17.44\n",
      "  Using cached botocore-1.17.44-py2.py3-none-any.whl (6.5 MB)\n",
      "Collecting aiohttp>=3.3.1\n",
      "  Using cached aiohttp-3.7.3-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting typing_extensions>=3.7\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (1.25.8)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (0.15.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (2.8.1)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-5.0.2-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (19.3.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (1.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (2.8)\n",
      "\u001b[31mERROR: boto3 1.16.13 has requirement botocore<1.20.0,>=1.19.13, but you'll have botocore 1.17.44 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.173 has requirement botocore==1.19.13, but you'll have botocore 1.17.44 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing-extensions, aioitertools, botocore, multidict, yarl, async-timeout, aiohttp, aiobotocore, fsspec, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.13\n",
      "    Uninstalling botocore-1.19.13:\n",
      "      Successfully uninstalled botocore-1.19.13\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.6.2\n",
      "    Uninstalling fsspec-0.6.2:\n",
      "      Successfully uninstalled fsspec-0.6.2\n",
      "Successfully installed aiobotocore-1.1.2 aiohttp-3.7.3 aioitertools-0.7.1 async-timeout-3.0.1 botocore-1.17.44 fsspec-0.8.4 multidict-5.0.2 s3fs-0.5.1 typing-extensions-3.7.4.3 yarl-1.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import os\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY_ID = 'AKIARJEUISD2VILSZ6HM'\n",
    "ACCESS_SECRET_KEY = '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'\n",
    "bucket = \"s3://williams-citibike/TripData/\"\n",
    "fs = s3fs.S3FileSystem(anon=False, key = ACCESS_KEY_ID, secret= ACCESS_SECRET_KEY)\n",
    "trip_filenames = fs.ls(\"s3://williams-citibike/TripData/\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stagingtable = \"\"\"\n",
    "           CREATE TABLE IF NOT EXISTS staging (\n",
    "               tripduration INTEGER, \n",
    "               starttime TIMESTAMP,\n",
    "               endtime TIMESTAMP,\n",
    "               startID NUMERIC,\n",
    "               startname VARCHAR(64),\n",
    "               start_lat REAL,\n",
    "               start_long REAL,\n",
    "               endID NUMERIC,\n",
    "               endname VARCHAR(64),\n",
    "               end_lat REAL,\n",
    "               end_long REAL,\n",
    "               bikeID INTEGER,\n",
    "               usertype VARCHAR(16),\n",
    "               birthyear REAL,\n",
    "               gender SMALLINT                \n",
    "          );\n",
    "          \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(stagingtable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_stage(datafile: str) -> None:\n",
    "    \"\"\"Grabs the data from the s3 bucket and edits it so that it can be uploaded to the staging table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datafile : str\n",
    "        The name of a file in the s3 bucket without the s3:// prefix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None:\n",
    "        If executed properly the database should now have rows corresponding to the rows in the data\n",
    "    \"\"\"\n",
    "    \n",
    "    datastream = StringIO()\n",
    "    \n",
    "    with fs.open(\"s3://\"+datafile, 'r') as file:\n",
    "        data = pd.read_csv(file, na_values =\"\") \n",
    "        data.fillna(-1, inplace=True) # Empty spaces need to be integers for birthyear column in database\n",
    "        \n",
    "        #Some stations have commas in their name causing the copy_from to register extra data fields\n",
    "        data.iloc[:, 4] = data.iloc[:, 4].str.replace(',','_')\n",
    "        data.iloc[:, 8] = data.iloc[:, 8].str.replace(',','_')\n",
    "        \n",
    "        # data.iloc[:, 3] = data.iloc[:, 3].astype('int32')\n",
    "        # data.iloc[:, 7] = data.iloc[:, 7].astype('int32')\n",
    "        \n",
    "        data.to_csv(datastream, index=False, header = False)\n",
    "        datastream.seek(0)\n",
    "\n",
    "        cursor.copy_from(datastream,'staging',sep=',')\n",
    "        conn.commit()\n",
    "    \n",
    "    datastream.close()\n",
    "    print(f\"Finished Uploading to Staging Table: {datafile}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Uploading to Raw: williams-citibike/TripData/2013-07 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-08 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-09 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-10 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-11 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-12 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/201306-citibike-tripdata.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "for file in trip_filenames:\n",
    "    populate_staging(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Station Table (Without the Neighborhood Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationtable = \"\"\"\n",
    "               CREATE TABLE IF NOT EXISTS station (\n",
    "                   stationID NUMERIC PRIMARY KEY,\n",
    "                   name VARCHAR(64) NOT NULL,\n",
    "                   latitude REAL,\n",
    "                   longitude REAL\n",
    "                );\n",
    "                \n",
    "                \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(stationtable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "               INSERT INTO station\n",
    "               SELECT DISTINCT ON(endid) endid, endname, end_lat, end_long \n",
    "                FROM staging \n",
    "               ORDER BY endid;\n",
    "               \"\"\"\n",
    "\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(insert_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Trip Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "triptable = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS trip (\n",
    "                startime TIMESTAMP,\n",
    "                endtime TIMESTAMP,\n",
    "                tripduration INTEGER,\n",
    "                startID NUMERIC,\n",
    "                endID NUMERIC,\n",
    "                usertype VARCHAR(16),\n",
    "                birthyear REAL,\n",
    "                gender SMALLINT\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(triptable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query2 = \"\"\"\n",
    "                INSERT INTO trip\n",
    "                SELECT starttime, endtime, tripduration, startid, endid, usertype, birthyear, gender\n",
    "                  FROM staging\n",
    "                 ORDER BY starttime, endtime;\n",
    "                \"\"\"\n",
    "\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(insert_query2)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Neighborhood Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt connection to the URL\n",
    "HoodURL = \"https://furmancenter.org/neighborhoods\"\n",
    "try:\n",
    "    r2 = requests.get(HoodURL)\n",
    "    r2.raise_for_status()\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(errh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r2.content, \"html.parser\")\n",
    "\n",
    "# The website has a dropdown with all the neighborhood codes and names\n",
    "hood_code_names = []\n",
    "\n",
    "#Instead of creating a dictionary like before, we create a list of tuples so that we can make a df\n",
    "for code in soup.find_all('option')[1:]:\n",
    "    hood_code_names.append((code.text[:4], code.text[6:].replace(\"/\",\"-\").replace(\" \",\"_\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_df = pd.DataFrame(hood_code_names, columns=[\"Code\", \"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough = {\n",
    "        \"BK\": \"Brooklyn\", \n",
    "        \"BX\": \"Bronx\",\n",
    "        \"MN\": \"Manhattan\",\n",
    "        \"QN\": \"Queens\",\n",
    "        \"SI\": \"Staten\"\n",
    "        }\n",
    "\n",
    "hood_df[\"Borough\"] = hood_df[\"Code\"].str[0:2].map(borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodtable = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS neighborhood (\n",
    "                code CHAR(4) PRIMARY KEY,\n",
    "                hoodname VARCHAR NOT NULL,\n",
    "                borough VARCHAR(16) NOT NULL\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(hoodtable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodstream = StringIO()\n",
    "\n",
    "hood_df.to_csv(hoodstream, index=False, header = False)\n",
    "hoodstream.seek(0)\n",
    "\n",
    "cursor.copy_from(hoodstream,'neighborhood',sep=',')\n",
    "conn.commit()\n",
    "    \n",
    "hoodstream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING: Creating a Neighborhood Profile Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_filenames = fs.ls(\"s3://williams-citibike/HoodData/\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the file from the bucket\n",
    "cols_lst = [0,3,8]\n",
    "names_lst = [\"code\", \"indicator\", \"2018\"]\n",
    "\n",
    "file = \"s3://\" + hood_filenames[0]\n",
    "data = pd.read_excel(file, sheet_name=1, usecols = cols_lst, names = names_lst)\n",
    "\n",
    "# Prep the '2018' column so that it can used as the value argument in the pivot_table \n",
    "data['2018'] = data['2018'].str.replace('$',\"\")\n",
    "data['2018'] = data['2018'].str.replace(',',\"\")\n",
    "\n",
    "# Values that are percents get turned into decimals\n",
    "for index, value in data['2018'].items():\n",
    "    if isinstance(value,str):\n",
    "        if value[-1] == '%':\n",
    "            data['2018'][index] = float(value.strip('%')) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['2018'] = pd.to_numeric(data['2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.pivot_table(index=['code'],values='2018', columns='indicator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename_axis(None, axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = data['code'][0].replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>Born in New York State</th>\n",
       "      <th>Car-free commute (% of commuters)</th>\n",
       "      <th>Disabled population</th>\n",
       "      <th>FHA/VA-backed home purchase loans (% of home purchase loans)</th>\n",
       "      <th>Foreign-born population</th>\n",
       "      <th>Home purchase loan rate (per 1,000 properties)</th>\n",
       "      <th>Home purchase loans in LMI tracts (% of home purchase loans)</th>\n",
       "      <th>Home purchase loans to LMI borrowers (% of home purchase loans)</th>\n",
       "      <th>Homeownership rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Severely rent-burdened households</th>\n",
       "      <th>Severely rent-burdened households, low income</th>\n",
       "      <th>Severely rent-burdened households, moderate income</th>\n",
       "      <th>Single-person households</th>\n",
       "      <th>Students performing at grade level in English language arts, 4th grade</th>\n",
       "      <th>Students performing at grade level in math, 4th grade</th>\n",
       "      <th>Total housing code violations (per 1,000 privately owned rental units)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Units authorized by new residential building permits</th>\n",
       "      <th>Units issued new certificates of occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BK01</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.493</td>\n",
       "      <td>173.6</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>2472.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   code  Born in New York State  Car-free commute (% of commuters)  \\\n",
       "0  BK01                   0.518                               0.85   \n",
       "\n",
       "   Disabled population  \\\n",
       "0                0.059   \n",
       "\n",
       "   FHA/VA-backed home purchase loans (% of home purchase loans)  \\\n",
       "0                                              0.002              \n",
       "\n",
       "   Foreign-born population  Home purchase loan rate (per 1,000 properties)  \\\n",
       "0                      0.2                                            21.7   \n",
       "\n",
       "   Home purchase loans in LMI tracts (% of home purchase loans)  \\\n",
       "0                                              0.242              \n",
       "\n",
       "   Home purchase loans to LMI borrowers (% of home purchase loans)  \\\n",
       "0                                              0.024                 \n",
       "\n",
       "   Homeownership rate  ...  Severely rent-burdened households  \\\n",
       "0               0.158  ...                              0.267   \n",
       "\n",
       "   Severely rent-burdened households, low income  \\\n",
       "0                                          0.485   \n",
       "\n",
       "   Severely rent-burdened households, moderate income  \\\n",
       "0                                              0.084    \n",
       "\n",
       "   Single-person households  \\\n",
       "0                     0.273   \n",
       "\n",
       "   Students performing at grade level in English language arts, 4th grade  \\\n",
       "0                                              0.518                        \n",
       "\n",
       "   Students performing at grade level in math, 4th grade  \\\n",
       "0                                              0.493       \n",
       "\n",
       "   Total housing code violations (per 1,000 privately owned rental units)  \\\n",
       "0                                              173.6                        \n",
       "\n",
       "   Unemployment rate  Units authorized by new residential building permits  \\\n",
       "0             0.0245                                             1097.0      \n",
       "\n",
       "   Units issued new certificates of occupancy  \n",
       "0                                      2472.0  \n",
       "\n",
       "[1 rows x 80 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
