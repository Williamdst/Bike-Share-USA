{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the Database\n",
    "\n",
    "Each citibike file has the same format, the colomns in the files are:\n",
    "- Trip Duration (seconds)\n",
    "- Start Date & Time\n",
    "- End Date & Time\n",
    "- Start Station ID\n",
    "- Start Station Name\n",
    "- Start Station Latitude\n",
    "- Start Station Longitude\n",
    "- End Date & Time\n",
    "- End Station ID\n",
    "- End Station Name\n",
    "- End Station Latitude\n",
    "- End Station Longitude\n",
    "- Bike ID\n",
    "- User Type\n",
    "- Gender\n",
    "- Year of Birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DatabaseDiagram.png\" width=\"600\" height=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.8.6-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.8.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the password in \n",
    "PGHOST = 'tripdatabase.cmaaautpgbsf.us-east-2.rds.amazonaws.com'\n",
    "PGDATABASE = ''\n",
    "PGUSER = 'postgres'\n",
    "PGPASSWORD = 'Josh1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success: ('PostgreSQL 12.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11), 64-bit',) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    # Set up a connection to the postgres server.    \n",
    "    conn = psycopg2.connect(user = PGUSER,\n",
    "                            port = \"5432\",\n",
    "                            password = PGPASSWORD,\n",
    "                            host = PGHOST,\n",
    "                            database = PGDATABASE)\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()   \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    record = cursor.fetchone()\n",
    "    print(\"Connection Success:\", record,\"\\n\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Raw Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Using cached s3fs-0.5.1-py3-none-any.whl (21 kB)\n",
      "Collecting fsspec>=0.8.0\n",
      "  Using cached fsspec-0.8.4-py3-none-any.whl (91 kB)\n",
      "Collecting aiobotocore>=1.0.1\n",
      "  Using cached aiobotocore-1.1.2-py3-none-any.whl (45 kB)\n",
      "Collecting aiohttp>=3.3.1\n",
      "  Using cached aiohttp-3.7.3-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Using cached aioitertools-0.7.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.17.45,>=1.17.44\n",
      "  Using cached botocore-1.17.44-py2.py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs) (1.11.2)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (3.0.4)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-5.0.2-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (19.3.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting typing-extensions>=3.6.5\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (0.15.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (2.8.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (1.14.0)\n",
      "\u001b[31mERROR: boto3 1.16.13 has requirement botocore<1.20.0,>=1.19.13, but you'll have botocore 1.17.44 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.173 has requirement botocore==1.19.13, but you'll have botocore 1.17.44 which is incompatible.\u001b[0m\n",
      "Installing collected packages: fsspec, multidict, typing-extensions, yarl, async-timeout, aiohttp, aioitertools, botocore, aiobotocore, s3fs\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.6.2\n",
      "    Uninstalling fsspec-0.6.2:\n",
      "      Successfully uninstalled fsspec-0.6.2\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.13\n",
      "    Uninstalling botocore-1.19.13:\n",
      "      Successfully uninstalled botocore-1.19.13\n",
      "Successfully installed aiobotocore-1.1.2 aiohttp-3.7.3 aioitertools-0.7.1 async-timeout-3.0.1 botocore-1.17.44 fsspec-0.8.4 multidict-5.0.2 s3fs-0.5.1 typing-extensions-3.7.4.3 yarl-1.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import os\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY_ID = 'AKIARJEUISD2VILSZ6HM'\n",
    "ACCESS_SECRET_KEY = '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'\n",
    "bucket = \"s3://williams-citibike/TripData/\"\n",
    "fs = s3fs.S3FileSystem(anon=False, key = ACCESS_KEY_ID, secret= ACCESS_SECRET_KEY)\n",
    "trip_filenames = fs.ls(\"s3://williams-citibike/TripData/\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtable = \"\"\"\n",
    "           CREATE TABLE IF NOT EXISTS raw (\n",
    "               tripduration INTEGER, \n",
    "               starttime TIMESTAMP,\n",
    "               endtime TIMESTAMP,\n",
    "               startID NUMERIC,\n",
    "               startname VARCHAR(64),\n",
    "               start_lat REAL,\n",
    "               start_long REAL,\n",
    "               endID NUMERIC,\n",
    "               endname VARCHAR(64),\n",
    "               end_lat REAL,\n",
    "               end_long REAL,\n",
    "               bikeID INTEGER,\n",
    "               usertype VARCHAR(16),\n",
    "               birthyear REAL,\n",
    "               gender SMALLINT                \n",
    "          );\n",
    "          \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(rawtable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_raw(datafile: str) -> None:\n",
    "    datastream = StringIO()\n",
    "    \n",
    "    with fs.open(\"s3://\"+datafile, 'r') as file:\n",
    "        data = pd.read_csv(file, na_values =\"\") \n",
    "        data.fillna(-1, inplace=True) # Empty spaces need to be integers for birthyear\n",
    "        \n",
    "        #Some stations have commas in their name cause the copy_from to register extra data fields\n",
    "        data.iloc[:, 4] = data.iloc[:, 4].str.replace(',','_')\n",
    "        data.iloc[:, 8] = data.iloc[:, 8].str.replace(',','_')\n",
    "        \n",
    "        # data.iloc[:, 3] = data.iloc[:, 3].astype('int32')\n",
    "        # data.iloc[:, 7] = data.iloc[:, 7].astype('int32')\n",
    "        \n",
    "        data.to_csv(datastream, index=False, header = False)\n",
    "        datastream.seek(0)\n",
    "\n",
    "        cursor.copy_from(datastream,'raw',sep=',')\n",
    "        conn.commit()\n",
    "    \n",
    "    datastream.close()\n",
    "    print(f\"Finished Uploading to Raw: {datafile}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Uploading to Raw: williams-citibike/TripData/2013-07 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-08 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-09 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-10 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-11 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-12 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/201306-citibike-tripdata.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "for file in trip_filenames:\n",
    "    populate_raw(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Station Table (Without the Neighborhood Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationtable = \"\"\"\n",
    "               CREATE TABLE IF NOT EXISTS station (\n",
    "                   stationID NUMERIC PRIMARY KEY,\n",
    "                   name VARCHAR(64) NOT NULL,\n",
    "                   latitude REAL,\n",
    "                   longitude REAL\n",
    "                );\n",
    "                \n",
    "                \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(stationtable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "               INSERT INTO station\n",
    "               SELECT DISTINCT ON(endid) endid, endname, end_lat, end_long \n",
    "                FROM raw \n",
    "               ORDER BY endid;\n",
    "               \"\"\"\n",
    "\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(insert_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Trip Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "triptable = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS trip (\n",
    "                startime TIMESTAMP,\n",
    "                endtime TIMESTAMP,\n",
    "                tripduration INTEGER,\n",
    "                startID NUMERIC,\n",
    "                endID NUMERIC,\n",
    "                usertype VARCHAR(16),\n",
    "                birthyear REAL,\n",
    "                gender SMALLINT\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(triptable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query2 = \"\"\"\n",
    "                INSERT INTO trip\n",
    "                SELECT starttime, endtime, tripduration, startid, endid, usertype, birthyear, gender\n",
    "                  FROM raw\n",
    "                 ORDER BY starttime, endtime;\n",
    "                \"\"\"\n",
    "\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(insert_query2)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Neighborhood Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt connection to the URL\n",
    "HoodURL = \"https://furmancenter.org/neighborhoods\"\n",
    "try:\n",
    "    r2 = requests.get(HoodURL)\n",
    "    r2.raise_for_status()\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(errh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r2.content, \"html.parser\")\n",
    "\n",
    "# The website has a dropdown with all the neighborhood codes and names\n",
    "hood_code_names = []\n",
    "\n",
    "#Instead of creating a dictionary like before, we create a list of tuples\n",
    "for code in soup.find_all('option')[1:]:\n",
    "    hood_code_names.append((code.text[:4], code.text[6:].replace(\"/\",\"-\").replace(\" \",\"_\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_df = pd.DataFrame(hood_code_names, columns=[\"Code\", \"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough = {\n",
    "        \"BK\": \"Brooklyn\", \n",
    "        \"BX\": \"Bronx\",\n",
    "        \"MN\": \"Manhattan\",\n",
    "        \"QN\": \"Queens\",\n",
    "        \"SI\": \"Staten\"\n",
    "        }\n",
    "\n",
    "hood_df[\"Borough\"] = hood_df[\"Code\"].str[0:2].map(borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodtable = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS neighborhood (\n",
    "                code CHAR(4) PRIMARY KEY,\n",
    "                hoodname VARCHAR NOT NULL,\n",
    "                borough VARCHAR(16) NOT NULL\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(hoodtable)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodstream = StringIO()\n",
    "\n",
    "hood_df.to_csv(hoodstream, index=False, header = False)\n",
    "hoodstream.seek(0)\n",
    "\n",
    "cursor.copy_from(hoodstream,'neighborhood',sep=',')\n",
    "conn.commit()\n",
    "    \n",
    "hoodstream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['williams-citibike/HoodData/BK01_Greenpoint-Williamsburg.xlsx',\n",
       " 'williams-citibike/HoodData/BK02_Fort_Greene-Brooklyn_Heights.xlsx',\n",
       " 'williams-citibike/HoodData/BK03_Bedford_Stuyvesant.xlsx',\n",
       " 'williams-citibike/HoodData/BK04_Bushwick.xlsx',\n",
       " 'williams-citibike/HoodData/BK05_East_New_York-Starrett_City.xlsx',\n",
       " 'williams-citibike/HoodData/BK06_Park_Slope-Carroll_Gardens.xlsx',\n",
       " 'williams-citibike/HoodData/BK07_Sunset_Park.xlsx',\n",
       " 'williams-citibike/HoodData/BK08_Crown_Heights-Prospect_Heights.xlsx',\n",
       " 'williams-citibike/HoodData/BK09_South_Crown_Heights-Lefferts_Gardens.xlsx',\n",
       " 'williams-citibike/HoodData/BK10_Bay_Ridge-Dyker_Heights.xlsx',\n",
       " 'williams-citibike/HoodData/BK11_Bensonhurst.xlsx',\n",
       " 'williams-citibike/HoodData/BK12_Borough_Park.xlsx',\n",
       " 'williams-citibike/HoodData/BK13_Coney_Island.xlsx',\n",
       " 'williams-citibike/HoodData/BK14_Flatbush-Midwood.xlsx',\n",
       " 'williams-citibike/HoodData/BK15_Sheepshead_Bay.xlsx',\n",
       " 'williams-citibike/HoodData/BK16_Brownsville.xlsx',\n",
       " 'williams-citibike/HoodData/BK17_East_Flatbush.xlsx',\n",
       " 'williams-citibike/HoodData/BK18_Flatlands-Canarsie.xlsx',\n",
       " 'williams-citibike/HoodData/BX01_Mott_Haven-Melrose.xlsx',\n",
       " 'williams-citibike/HoodData/BX02_Hunts_Point-Longwood.xlsx',\n",
       " 'williams-citibike/HoodData/BX03_Morrisania-Crotona.xlsx',\n",
       " 'williams-citibike/HoodData/BX04_Highbridge-Concourse.xlsx',\n",
       " 'williams-citibike/HoodData/BX05_Fordham-University_Heights.xlsx',\n",
       " 'williams-citibike/HoodData/BX06_Belmont-East_Tremont.xlsx',\n",
       " 'williams-citibike/HoodData/BX07_Kingsbridge_Heights-Bedford.xlsx',\n",
       " 'williams-citibike/HoodData/BX08_Riverdale-Fieldston.xlsx',\n",
       " 'williams-citibike/HoodData/BX09_Parkchester-Soundview.xlsx',\n",
       " 'williams-citibike/HoodData/BX10_Throgs_Neck-Co-op_City.xlsx',\n",
       " 'williams-citibike/HoodData/BX11_Morris_Park-Bronxdale.xlsx',\n",
       " 'williams-citibike/HoodData/BX12_Williamsbridge-Baychester.xlsx',\n",
       " 'williams-citibike/HoodData/MN01_Financial_District.xlsx',\n",
       " 'williams-citibike/HoodData/MN02_Greenwich_Village-Soho.xlsx',\n",
       " 'williams-citibike/HoodData/MN03_Lower_East_Side-Chinatown.xlsx',\n",
       " 'williams-citibike/HoodData/MN04_Clinton-Chelsea.xlsx',\n",
       " 'williams-citibike/HoodData/MN05_Midtown.xlsx',\n",
       " 'williams-citibike/HoodData/MN06_Stuyvesant_Town-Turtle_Bay.xlsx',\n",
       " 'williams-citibike/HoodData/MN07_Upper_West_Side.xlsx',\n",
       " 'williams-citibike/HoodData/MN08_Upper_East_Side.xlsx',\n",
       " 'williams-citibike/HoodData/MN09_Morningside_Heights-Hamilton.xlsx',\n",
       " 'williams-citibike/HoodData/MN10_Central_Harlem.xlsx',\n",
       " 'williams-citibike/HoodData/MN11_East_Harlem.xlsx',\n",
       " 'williams-citibike/HoodData/MN12_Washington_Heights-Inwood.xlsx',\n",
       " 'williams-citibike/HoodData/QN01_Astoria.xlsx',\n",
       " 'williams-citibike/HoodData/QN02_Woodside-Sunnyside.xlsx',\n",
       " 'williams-citibike/HoodData/QN03_Jackson_Heights.xlsx',\n",
       " 'williams-citibike/HoodData/QN04_Elmhurst-Corona.xlsx',\n",
       " 'williams-citibike/HoodData/QN05_Ridgewood-Maspeth.xlsx',\n",
       " 'williams-citibike/HoodData/QN06_Rego_Park-Forest_Hills.xlsx',\n",
       " 'williams-citibike/HoodData/QN07_Flushing-Whitestone.xlsx',\n",
       " 'williams-citibike/HoodData/QN08_Hillcrest-Fresh_Meadows.xlsx',\n",
       " 'williams-citibike/HoodData/QN09_Kew_Gardens-Woodhaven.xlsx',\n",
       " 'williams-citibike/HoodData/QN10_South_Ozone_Park-Howard_Beach.xlsx',\n",
       " 'williams-citibike/HoodData/QN11_Bayside-Little_Neck.xlsx',\n",
       " 'williams-citibike/HoodData/QN12_Jamaica-Hollis.xlsx',\n",
       " 'williams-citibike/HoodData/QN13_Queens_Village.xlsx',\n",
       " 'williams-citibike/HoodData/QN14_Rockaway-Broad_Channel.xlsx',\n",
       " 'williams-citibike/HoodData/SI01_St._George-Stapleton.xlsx',\n",
       " 'williams-citibike/HoodData/SI02_South_Beach-Willowbrook.xlsx',\n",
       " 'williams-citibike/HoodData/SI03_Tottenville-Great_Kills.xlsx']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hood_filenames = fs.ls(\"s3://williams-citibike/HoodData/\")[1:]\n",
    "hood_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_lst = [0,1,2,3,4,8,13]\n",
    "names_lst = [\"code\",\"name\",\"indicator_cat\", \"indicator\",\"indicator_descr\", \"2018\", \"2018-19_Rank\"]\n",
    "\n",
    "file = \"s3://\" + hood_filenames[0]\n",
    "data = pd.read_excel(file, sheet_name=1, usecols = cols_lst, names = names_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The percentage of city residents who were born in New York State.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['indicator_descr'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_database(datafile: str) -> None:\n",
    "    cols = [\"starttime\",\"stoptime\",\"tripduration\",\"start station id\", \"end station id\"]\n",
    "    datastream = StringIO()\n",
    "    \n",
    "    with fs.open(\"s3://\"+datafile, 'r') as f:\n",
    "        data = pd.read_csv(f, usecols=cols, parse_dates = ['starttime','stoptime'])\n",
    "        data = data[cols]\n",
    "        data.rename(columns={\"stoptime\":\"endtime\", \"start station id\":\"startID\", \"end station id\":\"endID\"}, inplace=True)\n",
    "        \n",
    "        data.to_csv(datastream, index=False, header = False)\n",
    "        datastream.seek(0)\n",
    "\n",
    "        cursor.copy_from(datastream,'trip',sep=',')\n",
    "        conn.commit()\n",
    "    \n",
    "    datastream.close()\n",
    "    print(f\"F {datafile}\")\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
