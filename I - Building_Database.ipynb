{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the Database\n",
    "\n",
    "Each citibike file records information about every single trip that was taken during a single month of the year. There are files for each month starting from June 2013. Each citibike file has the same format. The order and the description of the colomns are as follows:\n",
    "- Trip Duration (seconds): The length of the trip in seconds\n",
    "- Start Date & Time: The start time of the trip MM-DD-YYYY HH:MM:SS\n",
    "- End Date & Time: The end time of the trip MM-DD-YYYY HH:MM:SS\n",
    "- Start Station ID: The ID for the station where the trip started\n",
    "- Start Station Name: The name of the station where the trip started\n",
    "- Start Station Latitude: The latitude of the station where the trip started\n",
    "- Start Station Longitude: The longitude of the station where the trip started\n",
    "- End Station ID: The ID for the station where the trip ended\n",
    "- End Station Name: The name of the station where the trip ended\n",
    "- End Station Latitude: The latitude of the station where the trip ended\n",
    "- End Station Longitude: The longitude of the station where the trip ended\n",
    "- Bike ID: The ID for the bike that was used in the trip\n",
    "- User Type: What type of user took the trip (Subscriber or Customer)\n",
    "- Gender: The gender of the user (Male - 1, Female - 2, None - 0)\n",
    "- Year of Birth: The year that the user was born"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DatabaseDiagram.png\" width=\"600\" height=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.8.6-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.8.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the password in \n",
    "PGHOST = 'tripdatabase.cmaaautpgbsf.us-east-2.rds.amazonaws.com'\n",
    "PGDATABASE = ''\n",
    "PGUSER = 'postgres'\n",
    "PGPASSWORD = 'Josh1234'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Success: ('PostgreSQL 12.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11), 64-bit',) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    # Set up a connection to the postgres server.    \n",
    "    conn = psycopg2.connect(user = PGUSER,\n",
    "                            port = \"5432\",\n",
    "                            password = PGPASSWORD,\n",
    "                            host = PGHOST,\n",
    "                            database = PGDATABASE)\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()   \n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    record = cursor.fetchone()\n",
    "    print(\"Connection Success:\", record,\"\\n\")\n",
    "\n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Staging Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Using cached s3fs-0.5.1-py3-none-any.whl (21 kB)\n",
      "Collecting aiobotocore>=1.0.1\n",
      "  Using cached aiobotocore-1.1.2-py3-none-any.whl (45 kB)\n",
      "Collecting fsspec>=0.8.0\n",
      "  Using cached fsspec-0.8.4-py3-none-any.whl (91 kB)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.7/site-packages (from aiobotocore>=1.0.1->s3fs) (1.11.2)\n",
      "Collecting aiohttp>=3.3.1\n",
      "  Using cached aiohttp-3.7.3-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting botocore<1.17.45,>=1.17.44\n",
      "  Using cached botocore-1.17.44-py2.py3-none-any.whl (6.5 MB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Using cached aioitertools-0.7.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (19.3.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "Collecting typing-extensions>=3.6.5\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (3.0.4)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (0.15.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (1.25.8)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.45,>=1.17.44->aiobotocore>=1.0.1->s3fs) (1.14.0)\n",
      "\u001b[31mERROR: boto3 1.16.19 has requirement botocore<1.20.0,>=1.19.19, but you'll have botocore 1.17.44 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.179 has requirement botocore==1.19.19, but you'll have botocore 1.17.44 which is incompatible.\u001b[0m\n",
      "Installing collected packages: multidict, typing-extensions, yarl, async-timeout, aiohttp, botocore, aioitertools, aiobotocore, fsspec, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.19\n",
      "    Uninstalling botocore-1.19.19:\n",
      "      Successfully uninstalled botocore-1.19.19\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.6.2\n",
      "    Uninstalling fsspec-0.6.2:\n",
      "      Successfully uninstalled fsspec-0.6.2\n",
      "Successfully installed aiobotocore-1.1.2 aiohttp-3.7.3 aioitertools-0.7.1 async-timeout-3.0.1 botocore-1.17.44 fsspec-0.8.4 multidict-5.1.0 s3fs-0.5.1 typing-extensions-3.7.4.3 yarl-1.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import os\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY_ID = 'AKIARJEUISD2VILSZ6HM'\n",
    "ACCESS_SECRET_KEY = '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'\n",
    "bucket = \"s3://williams-citibike/TripData/\"\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False, key = ACCESS_KEY_ID, secret= ACCESS_SECRET_KEY)\n",
    "trip_filenames = fs.ls(\"s3://williams-citibike/TripData/\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_table_query = \"\"\"\n",
    "           CREATE TABLE IF NOT EXISTS staging (\n",
    "               tripduration INTEGER, \n",
    "               starttime TIMESTAMP,\n",
    "               endtime TIMESTAMP,\n",
    "               startID NUMERIC,\n",
    "               startname VARCHAR(64),\n",
    "               start_lat REAL,\n",
    "               start_long REAL,\n",
    "               endID NUMERIC,\n",
    "               endname VARCHAR(64),\n",
    "               end_lat REAL,\n",
    "               end_long REAL,\n",
    "               bikeID INTEGER,\n",
    "               usertype VARCHAR(16),\n",
    "               birthyear REAL,\n",
    "               gender SMALLINT                \n",
    "          );\n",
    "          \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(staging_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_stage(datafile: str) -> None:\n",
    "    \"\"\"Grabs the data from the s3 bucket and edits it so that it can be uploaded to the staging table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datafile : str\n",
    "        The name of a file in the s3 bucket without the s3:// prefix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None:\n",
    "        If executed properly the database should now have rows corresponding to the rows in the data\n",
    "    \"\"\"\n",
    "    \n",
    "    datastream = StringIO()\n",
    "    \n",
    "    with fs.open(\"s3://\"+datafile, 'r') as file:\n",
    "        data = pd.read_csv(file, na_values =\"\") \n",
    "        data.fillna(-1, inplace=True) # Empty spaces need to be integers for birthyear column in database\n",
    "        \n",
    "        #Some stations have commas in their name causing the copy_from to register extra data fields\n",
    "        data.iloc[:, 4] = data.iloc[:, 4].str.replace(',','_')\n",
    "        data.iloc[:, 8] = data.iloc[:, 8].str.replace(',','_')\n",
    "        \n",
    "        # data.iloc[:, 3] = data.iloc[:, 3].astype('int32')\n",
    "        # data.iloc[:, 7] = data.iloc[:, 7].astype('int32')\n",
    "        \n",
    "        data.to_csv(datastream, index=False, header = False)\n",
    "        datastream.seek(0)\n",
    "\n",
    "        cursor.copy_from(datastream,'staging',sep=',')\n",
    "        conn.commit()\n",
    "    \n",
    "    datastream.close()\n",
    "    print(f\"Finished Uploading to Staging Table: {datafile}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Uploading to Raw: williams-citibike/TripData/2013-07 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-08 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-09 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-10 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-11 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/2013-12 - Citi Bike trip data.csv\n",
      "Finished Uploading to Raw: williams-citibike/TripData/201306-citibike-tripdata.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "for file in trip_filenames:\n",
    "    populate_staging(file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Trip Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS trip (\n",
    "                startime TIMESTAMP,\n",
    "                endtime TIMESTAMP,\n",
    "                tripduration INTEGER,\n",
    "                startID NUMERIC,\n",
    "                endID NUMERIC,\n",
    "                usertype VARCHAR(16),\n",
    "                birthyear REAL,\n",
    "                gender SMALLINT\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(trip_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query2 = \"\"\"\n",
    "        INSERT INTO trip\n",
    "        SELECT starttime, endtime, tripduration, startid, endid, usertype, birthyear, gender\n",
    "          FROM staging\n",
    "         ORDER BY starttime, endtime;\n",
    "        \"\"\"\n",
    "\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(insert_query2)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Neighborhood Table I - Without the Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt connection to the URL\n",
    "HoodURL = \"https://furmancenter.org/neighborhoods\"\n",
    "try:\n",
    "    r2 = requests.get(HoodURL)\n",
    "    r2.raise_for_status()\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(errh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r2.content, \"html.parser\")\n",
    "\n",
    "# The website has a dropdown with all the neighborhood codes and names\n",
    "hood_code_names = []\n",
    "\n",
    "#Instead of creating a dictionary like before, we create a list of tuples so that we can make a df\n",
    "for code in soup.find_all('option')[1:]:\n",
    "    hood_code_names.append((code.text[:4], code.text[6:].replace(\"/\",\"-\").replace(\" \",\"_\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_df = pd.DataFrame(hood_code_names, columns=[\"code\", \"hoodname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough = {\n",
    "        \"BK\": \"Brooklyn\", \n",
    "        \"BX\": \"Bronx\",\n",
    "        \"MN\": \"Manhattan\",\n",
    "        \"QN\": \"Queens\",\n",
    "        \"SI\": \"Staten\"\n",
    "        }\n",
    "\n",
    "hood_df[\"borough\"] = hood_df[\"code\"].str[0:2].map(borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>hoodname</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BK01</td>\n",
       "      <td>Greenpoint-Williamsburg</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BK02</td>\n",
       "      <td>Fort_Greene-Brooklyn_Heights</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BK03</td>\n",
       "      <td>Bedford_Stuyvesant</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BK04</td>\n",
       "      <td>Bushwick</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BK05</td>\n",
       "      <td>East_New_York-Starrett_City</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                      hoodname   borough\n",
       "0  BK01       Greenpoint-Williamsburg  Brooklyn\n",
       "1  BK02  Fort_Greene-Brooklyn_Heights  Brooklyn\n",
       "2  BK03            Bedford_Stuyvesant  Brooklyn\n",
       "3  BK04                      Bushwick  Brooklyn\n",
       "4  BK05   East_New_York-Starrett_City  Brooklyn"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hood_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Neighborhood Table II - Adding the Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Using cached geopandas-0.8.1-py2.py3-none-any.whl (962 kB)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from geopandas) (1.0.1)\n",
      "Collecting fiona\n",
      "  Using cached Fiona-1.8.18-cp37-cp37m-manylinux1_x86_64.whl (14.8 MB)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Using cached pyproj-3.0.0.post1-cp37-cp37m-manylinux2010_x86_64.whl (6.4 MB)\n",
      "Collecting shapely\n",
      "  Using cached Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->geopandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->geopandas) (2019.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from fiona->geopandas) (2019.11.28)\n",
      "Requirement already satisfied: six>=1.7 in /opt/conda/lib/python3.7/site-packages (from fiona->geopandas) (1.14.0)\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/lib/python3.7/site-packages (from fiona->geopandas) (19.3.0)\n",
      "Collecting munch\n",
      "  Using cached munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting click-plugins>=1.0\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: click<8,>=4.0 in /opt/conda/lib/python3.7/site-packages (from fiona->geopandas) (7.0)\n",
      "Collecting cligj>=0.5\n",
      "  Using cached cligj-0.7.1-py3-none-any.whl (7.1 kB)\n",
      "Installing collected packages: munch, click-plugins, cligj, fiona, pyproj, shapely, geopandas\n",
      "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.18 geopandas-0.8.1 munch-2.5.0 pyproj-3.0.0.post1 shapely-1.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "geofile = \"s3://williams-citibike/Community_Districts.geojson\"\n",
    "\n",
    "with fs.open(geofile, 'rb') as file:\n",
    "    districts = gpd.read_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boro_cd</th>\n",
       "      <th>shape_area</th>\n",
       "      <th>shape_leng</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311</td>\n",
       "      <td>103177785.365</td>\n",
       "      <td>51549.5578567</td>\n",
       "      <td>MULTIPOLYGON (((-73.97299 40.60881, -73.97259 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>88195686.2748</td>\n",
       "      <td>65821.875577</td>\n",
       "      <td>MULTIPOLYGON (((-73.98372 40.59582, -73.98305 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>99525500.0655</td>\n",
       "      <td>52245.8304843</td>\n",
       "      <td>MULTIPOLYGON (((-73.97140 40.64826, -73.97121 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>42664311.3238</td>\n",
       "      <td>35875.7111725</td>\n",
       "      <td>MULTIPOLYGON (((-73.87185 40.84376, -73.87192 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226</td>\n",
       "      <td>50566410.6415</td>\n",
       "      <td>32820.3983295</td>\n",
       "      <td>MULTIPOLYGON (((-73.86790 40.90294, -73.86796 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boro_cd     shape_area     shape_leng  \\\n",
       "0     311  103177785.365  51549.5578567   \n",
       "1     313  88195686.2748   65821.875577   \n",
       "2     312  99525500.0655  52245.8304843   \n",
       "3     206  42664311.3238  35875.7111725   \n",
       "4     226  50566410.6415  32820.3983295   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-73.97299 40.60881, -73.97259 ...  \n",
       "1  MULTIPOLYGON (((-73.98372 40.59582, -73.98305 ...  \n",
       "2  MULTIPOLYGON (((-73.97140 40.64826, -73.97121 ...  \n",
       "3  MULTIPOLYGON (((-73.87185 40.84376, -73.87192 ...  \n",
       "4  MULTIPOLYGON (((-73.86790 40.90294, -73.86796 ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes from the Furman Center are exactly the same as the codes seen in the boro_cd column. However, the first number in the boro_cd acts as a category that represents the borough. The original Furman codes, seen in the hood_df, have to be reversed engineered using a maping. Once the mapping is complete, the two dataframes can be merged together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_num_to_abr = {\n",
    "        \"3\": \"BK\", \n",
    "        \"2\": \"BX\",\n",
    "        \"1\": \"MN\",\n",
    "        \"4\": \"QN\",\n",
    "        \"5\": \"SI\"\n",
    "        }\n",
    "\n",
    "districts[\"boro_cd\"] = districts[\"boro_cd\"].str[0].map(borough_num_to_abr) + districts['boro_cd'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = districts[['boro_cd','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_spatial = hood_df.merge(districts, left_on='code', right_on='boro_cd', how='left').loc[:,['code', 'hoodname', 'borough', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_spatial.sort_values(by='code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hood_spatial = gpd.GeoDataFrame(hood_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>hoodname</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BK01</td>\n",
       "      <td>Greenpoint-Williamsburg</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>MULTIPOLYGON (((-73.92406 40.71411, -73.92404 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BK02</td>\n",
       "      <td>Fort_Greene-Brooklyn_Heights</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>MULTIPOLYGON (((-73.96929 40.70709, -73.96839 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BK03</td>\n",
       "      <td>Bedford_Stuyvesant</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>MULTIPOLYGON (((-73.91805 40.68721, -73.91800 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BK04</td>\n",
       "      <td>Bushwick</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>MULTIPOLYGON (((-73.89647 40.68234, -73.89653 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BK05</td>\n",
       "      <td>East_New_York-Starrett_City</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>MULTIPOLYGON (((-73.86841 40.69473, -73.86868 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                      hoodname   borough  \\\n",
       "0  BK01       Greenpoint-Williamsburg  Brooklyn   \n",
       "1  BK02  Fort_Greene-Brooklyn_Heights  Brooklyn   \n",
       "2  BK03            Bedford_Stuyvesant  Brooklyn   \n",
       "3  BK04                      Bushwick  Brooklyn   \n",
       "4  BK05   East_New_York-Starrett_City  Brooklyn   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-73.92406 40.71411, -73.92404 ...  \n",
       "1  MULTIPOLYGON (((-73.96929 40.70709, -73.96839 ...  \n",
       "2  MULTIPOLYGON (((-73.91805 40.68721, -73.91800 ...  \n",
       "3  MULTIPOLYGON (((-73.89647 40.68234, -73.89653 ...  \n",
       "4  MULTIPOLYGON (((-73.86841 40.69473, -73.86868 ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hood_spatial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Neighborhood Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS neighborhood (\n",
    "                code CHAR(4) PRIMARY KEY,\n",
    "                hoodname VARCHAR NOT NULL,\n",
    "                borough VARCHAR(16) NOT NULL,\n",
    "                geometry GEOGRAPHY(MULTIPOLYGON,4326) NOT NULL\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(neighborhood_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoodstream = StringIO()\n",
    "\n",
    "hood_spatial.to_csv(hoodstream,sep='\\t', index=False, header=False)\n",
    "hoodstream.seek(0)\n",
    "\n",
    "cursor.copy_from(hoodstream,'neighborhood',sep='\\t')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Station Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_query = \"\"\"\n",
    "        SELECT DISTINCT ON(endid) endid, endname, end_lat, end_long \n",
    "          FROM staging \n",
    "         ORDER BY endid;\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations = pd.read_sql(stations_query, conn) # Expect long execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_spatial = gpd.GeoDataFrame(stations, geometry=gpd.points_from_xy(stations.end_long, stations.end_lat), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inner join will remove stations that aren't in NYC (some stations are in NJ).\n",
    "# Additionally it will remove the handful of stations that didn't have information other than the ID\n",
    "\n",
    "stations_spatial = gpd.sjoin(stations_spatial, hood_spatial, how='inner', op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_spatial = stations_spatial[['endid','endname','code','geometry']].rename(columns={'endid':'stationID','endname':'name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_spatial.name = stations_spatial.name.str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationID</th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>W 52 St &amp; 11 Ave</td>\n",
       "      <td>MN04</td>\n",
       "      <td>POINT (-73.99393 40.76727)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>116.0</td>\n",
       "      <td>W 17 St &amp; 8 Ave</td>\n",
       "      <td>MN04</td>\n",
       "      <td>POINT (-74.00150 40.74178)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>212.0</td>\n",
       "      <td>W 16 St &amp; The High Line</td>\n",
       "      <td>MN04</td>\n",
       "      <td>POINT (-74.00682 40.74335)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>334.0</td>\n",
       "      <td>W 20 St &amp; 7 Ave</td>\n",
       "      <td>MN04</td>\n",
       "      <td>POINT (-73.99726 40.74239)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>388.0</td>\n",
       "      <td>W 26 St &amp; 10 Ave</td>\n",
       "      <td>MN04</td>\n",
       "      <td>POINT (-74.00295 40.74972)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stationID                     name  code                    geometry\n",
       "1         72.0         W 52 St & 11 Ave  MN04  POINT (-73.99393 40.76727)\n",
       "5        116.0          W 17 St & 8 Ave  MN04  POINT (-74.00150 40.74178)\n",
       "28       212.0  W 16 St & The High Line  MN04  POINT (-74.00682 40.74335)\n",
       "123      334.0          W 20 St & 7 Ave  MN04  POINT (-73.99726 40.74239)\n",
       "171      388.0         W 26 St & 10 Ave  MN04  POINT (-74.00295 40.74972)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_spatial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the Station Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_table_query = \"\"\"\n",
    "               CREATE TABLE IF NOT EXISTS station (\n",
    "                   stationID NUMERIC PRIMARY KEY,\n",
    "                   name VARCHAR(64) NOT NULL,\n",
    "                   code CHAR(4) NOT NULL,\n",
    "                   geometry GEOGRAPHY(POINT,4326) NOT NULL\n",
    "                );\n",
    "                \n",
    "                \"\"\"\n",
    "cursor.execute(\"rollback;\")\n",
    "cursor.execute(station_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationstream = StringIO()\n",
    "stations_spatial.to_csv(stationstream,sep='\\t', index=False, header=False)\n",
    "stationstream.seek(0)\n",
    "\n",
    "cursor.copy_from(stationstream,'station',sep='\\t')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import csv into df \n",
    "\"\"\"\n",
    "Iterate through the csv and add columns using the name of the columns in the df\n",
    "\n",
    "for name in df.columns:\n",
    "    ALTER TABLE table_name\n",
    "    ADD COLUMN name data_type constraint;\n",
    "    \n",
    "    for code in neighborhood['code']:\n",
    "        value = neighborhood.loc[neighborhood[code]==code,name]\n",
    "        \n",
    "        UPDATE table_name\n",
    "        SET name = value,\n",
    "        where code = code;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a csv sep+ = '\\t'"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
